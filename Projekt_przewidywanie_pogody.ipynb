{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awaw24/Weather_Forecast_Project/blob/main/Projekt_przewidywanie_pogody.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Źródło danych:**\n",
        "https://www.kaggle.com/datasets/selfishgene/historical-hourly-weather-data"
      ],
      "metadata": {
        "id": "R_uk2QlTse4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicjalizacja"
      ],
      "metadata": {
        "id": "SXIqSAInxY2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "uqbQunSOMqUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhZoNG_e2RBy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found, przestaw środowisko wykonawcze do obsługi T4 GPU (wykonuje obliczenia ponad 2x szybciej). Kliknij, Środowisko wykonawcze --> Zmień typ środowiska wykonawczego --> Akcelerator sprzętowy == T4 GPU --> ZAPISZ')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# Ustawienia konfiguracyjne dla wykresów\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Upload the kaggle.json file\n",
        "#uploaded = files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "#!cp kaggle.json ~/.kaggle/\n",
        "!echo '{\"username\":\"arkadiuszpizon\",\"key\":\"3c3a9f417acea444ab7079f157abb429\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d selfishgene/historical-hourly-weather-data\n",
        "!unzip -qn historical-hourly-weather-data.zip"
      ],
      "metadata": {
        "id": "lVh9g25jMtvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wczytanie plików"
      ],
      "metadata": {
        "id": "IhqAKqwPxc51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temperature = pd.read_csv('temperature.csv')\n",
        "df_humidity = pd.read_csv('humidity.csv')\n",
        "df_pressure = pd.read_csv('pressure.csv')\n",
        "df_weather_description = pd.read_csv('weather_description.csv')\n",
        "df_wind_direction = pd.read_csv('wind_direction.csv')\n",
        "df_wind_speed = pd.read_csv('wind_speed.csv')"
      ],
      "metadata": {
        "id": "yHrj0jukN7Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wstępna weryfkiacja"
      ],
      "metadata": {
        "id": "4MwR3pNnxmLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temperature.head()"
      ],
      "metadata": {
        "id": "AexbLdQGvQTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analiza pod względem braku danych dla poszczególnych miast"
      ],
      "metadata": {
        "id": "0bttoePMo99O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = [df_temperature, df_humidity, df_pressure, df_weather_description, df_wind_direction, df_wind_speed]\n",
        "new_column_names = [\"temp\", \"humid\", \"press\", \"descr\", \"w_dir\", \"w_speed\"]\n",
        "nan_counts = pd.concat([df.isnull().sum() for df in dfs], axis=1, keys=new_column_names)\n",
        "\n",
        "nan_counts['Row_Sum'] = nan_counts.sum(axis=1)\n",
        "nan_counts_sorted = nan_counts.sort_values(by='Row_Sum', ascending=True)\n",
        "\n",
        "print(\"NaN occurrences in each column:\")\n",
        "print(nan_counts_sorted)"
      ],
      "metadata": {
        "id": "SSgdSPYMo8k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wybieranie danych dla **San Diego** i połączenie dataframe'ów w jedno"
      ],
      "metadata": {
        "id": "1KDF7ju1oi1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temperature = pd.read_csv('temperature.csv')\n",
        "df_humidity = pd.read_csv('humidity.csv')\n",
        "df_pressure = pd.read_csv('pressure.csv')\n",
        "df_weather_description = pd.read_csv('weather_description.csv')\n",
        "df_wind_direction = pd.read_csv('wind_direction.csv')\n",
        "df_wind_speed = pd.read_csv('wind_speed.csv')\n",
        "\n",
        "city = 'San Diego'\n",
        "df_datetime = pd.to_datetime(df_temperature['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
        "df_temperature = df_temperature[[city]].rename(columns={city: 'temperature'})\n",
        "df_humidity = df_humidity[[city]].rename(columns={city: 'humidity'})\n",
        "df_pressure = df_pressure[[city]].rename(columns={city: 'pressure'})\n",
        "df_weather_description = df_weather_description[[city]].rename(columns={city: 'description'})\n",
        "df_wind_direction = df_wind_direction[[city]].rename(columns={city: 'wind_dir'})\n",
        "df_wind_speed = df_wind_speed[[city]].rename(columns={city: 'wind_speed'})\n",
        "\n",
        "df_weather = pd.concat([df_datetime, df_temperature, df_humidity, df_pressure, df_weather_description, df_wind_direction, df_wind_speed], axis=1)"
      ],
      "metadata": {
        "id": "dWfW2Pwoi36a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dane na których pracuję to __df_weather__ i dotyczą miasta **San Diego**"
      ],
      "metadata": {
        "id": "U7qE2Hp45caF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.head()"
      ],
      "metadata": {
        "id": "fPin62SM5ON9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_count = df_weather[['description']].value_counts()\n",
        "print(weather_count)"
      ],
      "metadata": {
        "id": "Vva1bzfIQgKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analiza pod kątem występowania braku danych w DataFramie dla San Diego"
      ],
      "metadata": {
        "id": "cVOH08hk34hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyświetlenie liczby brakujących danych w poszczególnych kolumnach"
      ],
      "metadata": {
        "id": "XdIX_tYE2nIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.isna().sum()"
      ],
      "metadata": {
        "id": "Fjc2mN8x0qGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyświetlenie wszystkich wierszy w których występują braki"
      ],
      "metadata": {
        "id": "1JORTIR-2jtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_values = df_weather[df_weather.isna().any(axis=1)]\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "print (nan_values)"
      ],
      "metadata": {
        "id": "CUa-jKnJ0tx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hum_mean = df_weather.loc[:,\"humidity\"].mean()\n",
        "press_mean = df_weather.loc[:,\"pressure\"].mean()\n",
        "df_weather = df_weather.fillna(value={'humidity':hum_mean,'pressure':press_mean,'temperature':291.530000,'description': \"sky is clear\",'wind_dir':0.0,'wind_speed':0.0 })"
      ],
      "metadata": {
        "id": "6dQC8E0o-dvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyświetlenie liczby brakujących danych w poszczególnych kolumnach"
      ],
      "metadata": {
        "id": "XXYK3j1V2zSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.isna().sum()"
      ],
      "metadata": {
        "id": "XJ4xP2uS0ZGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyświetlenie wszystkich wierszy w których występują braki"
      ],
      "metadata": {
        "id": "wfrLZ0vg2bFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_values = df_weather[df_weather.isna().any(axis=1)]\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "print (nan_values)"
      ],
      "metadata": {
        "id": "70rVF9Hm0buD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dodanie kolumn: **rain_exists** oraz **cloud_ exists**"
      ],
      "metadata": {
        "id": "Qo2HcVUADzHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie wartości przed zmianą"
      ],
      "metadata": {
        "id": "C_D7t23NR3Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.head()"
      ],
      "metadata": {
        "id": "zwptnvL7pIr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tworzenie kolumny **rain_exists**"
      ],
      "metadata": {
        "id": "KxHtAOTujwZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.loc[(df_weather['description'] == 'light rain') | (df_weather['description'] == 'moderate rain') | (df_weather['description'] == 'light intensity drizzle') | (df_weather['description'] == 'drizzle') | (df_weather['description'] == 'squalls') | (df_weather['description'] == 'heavy intensity rain') | (df_weather['description'] == 'thunderstorm') | (df_weather['description'] == 'shower rain') | (df_weather['description'] == 'very heavy rain') | (df_weather['description'] == 'thunderstorm with light rain') | (df_weather['description'] == 'thunderstorm with rain') | (df_weather['description'] == 'light intensity shower rain'), 'rain_exists'] = 1\n",
        "df_weather.loc[(df_weather['description'] != 'light rain') & (df_weather['description'] != 'moderate rain') & (df_weather['description'] != 'light intensity drizzle') & (df_weather['description'] != 'drizzle') & (df_weather['description'] != 'squalls') & (df_weather['description'] != 'heavy intensity rain') & (df_weather['description'] != 'thunderstorm') & (df_weather['description'] != 'shower rain') & (df_weather['description'] != 'very heavy rain') & (df_weather['description'] != 'thunderstorm with light rain') & (df_weather['description'] != 'thunderstorm with rain') & (df_weather['description'] != 'light intensity shower rain'), 'rain_exists'] = 0\n",
        "\n",
        "df_weather['rain_exists'] = df_weather['rain_exists'].astype('bool')"
      ],
      "metadata": {
        "id": "K8jtVbdzDyW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tworzenie kolumny **cloud_exists**"
      ],
      "metadata": {
        "id": "PyEhFyl7j4Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.loc[(df_weather['description'] == 'light rain') | (df_weather['description'] == 'moderate rain') | (df_weather['description'] == 'light intensity drizzle') | (df_weather['description'] == 'drizzle') | (df_weather['description'] == 'squalls') | (df_weather['description'] == 'heavy intensity rain') | (df_weather['description'] == 'thunderstorm') | (df_weather['description'] == 'shower rain') | (df_weather['description'] == 'very heavy rain') | (df_weather['description'] == 'thunderstorm with light rain') | (df_weather['description'] == 'thunderstorm with rain') | (df_weather['description'] == 'light intensity shower rain') | (df_weather['description'] == 'few clouds') | (df_weather['description'] == 'scattered clouds') | (df_weather['description'] == 'broken clouds') | (df_weather['description'] == 'overcast clouds') | (df_weather['description'] == 'proximity thunderstorm'), 'cloud_exists'] = 1\n",
        "df_weather.loc[(df_weather['description'] != 'light rain') & (df_weather['description'] != 'moderate rain') & (df_weather['description'] != 'light intensity drizzle') & (df_weather['description'] != 'drizzle') & (df_weather['description'] != 'squalls') & (df_weather['description'] != 'heavy intensity rain') & (df_weather['description'] != 'thunderstorm') & (df_weather['description'] != 'shower rain') & (df_weather['description'] != 'very heavy rain') & (df_weather['description'] != 'thunderstorm with light rain') & (df_weather['description'] != 'thunderstorm with rain') & (df_weather['description'] != 'light intensity shower rain') & (df_weather['description'] != 'few clouds') & (df_weather['description'] != 'scattered clouds') & (df_weather['description'] != 'broken clouds') & (df_weather['description'] != 'overcast clouds') & (df_weather['description'] != 'proximity thunderstorm'), 'cloud_exists'] = 0\n",
        "\n",
        "df_weather['cloud_exists'] = df_weather['cloud_exists'].astype('bool')"
      ],
      "metadata": {
        "id": "qRSgSpG_JXXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usuwanie kolumny **description**"
      ],
      "metadata": {
        "id": "iIOZhpOTb-zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.drop(['description'], inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "0DjkmA_Lbqjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie wartości po zmianie"
      ],
      "metadata": {
        "id": "6gziUfSCtVyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.head()"
      ],
      "metadata": {
        "id": "xaWVukiftGwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie typów danych w kolumnach **rain** i **cloud**"
      ],
      "metadata": {
        "id": "CkcMuf7pqZyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.info(verbose=True)"
      ],
      "metadata": {
        "id": "19qzGRyTQHo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_cols = ['temperature', 'humidity', 'pressure']\n",
        "plot_features = df_weather[plot_cols]\n",
        "plot_features.index = df_weather['datetime']\n",
        "_ = plot_features.plot(subplots=True)\n",
        "\n",
        "plot_features = df_weather[plot_cols][:2400]\n",
        "plot_features.index = df_weather['datetime'][:2400]\n",
        "_ = plot_features.plot(subplots=True)"
      ],
      "metadata": {
        "id": "5PpqdsZYs4kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przeliczenie wiatru z wartści kierunku w stopniach na współrzędne **x** oraz **y**"
      ],
      "metadata": {
        "id": "saoF6mDD1GwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_count = df_weather[['wind_speed']].value_counts()\n",
        "print(weather_count)"
      ],
      "metadata": {
        "id": "7VLCkLIS1NDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist2d(df_weather['wind_dir'], df_weather['wind_speed'], bins=(50, 15), vmax=100)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind Direction [deg]')\n",
        "plt.ylabel('Wind Velocity [m/s]')"
      ],
      "metadata": {
        "id": "FMnqhQqtsAmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wv = df_weather.pop('wind_speed')\n",
        "\n",
        "# Konwersja na radiany\n",
        "wd_rad = df_weather.pop('wind_dir')*np.pi / 180\n",
        "\n",
        "# Wyliczanie składowe x oraz y\n",
        "df_weather['Wx'] = wv*np.cos(wd_rad)\n",
        "df_weather['Wy'] = wv*np.sin(wd_rad)"
      ],
      "metadata": {
        "id": "31riNeUB0gUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist2d(df_weather['Wx'], df_weather['Wy'], bins=(30, 30), vmax=30, range=[[-30, 30], [-30, 30]])\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind X [m/s]')\n",
        "plt.ylabel('Wind Y [m/s]')\n",
        "ax = plt.gca()\n",
        "ax.axis('tight')"
      ],
      "metadata": {
        "id": "LZS0jkuC0401"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.head()"
      ],
      "metadata": {
        "id": "6uynjfdY92xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konwersja czasu na funkcję **Sin** i **Cos**\n",
        "\n"
      ],
      "metadata": {
        "id": "hKvQqw9Wb8zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(df_weather)\n",
        "\n",
        "date_time = pd.to_datetime(df.pop('datetime'), format='%d.%m.%Y %H:%M:%S')"
      ],
      "metadata": {
        "id": "S7mKxQjdS3mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp_s = date_time.map(pd.Timestamp.timestamp)"
      ],
      "metadata": {
        "id": "V-uQpCaFQciR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "df_weather['day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "df_weather['day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "df_weather['year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "df_weather['year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ],
      "metadata": {
        "id": "69533e5SOqYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.array(df_weather['day sin'])[:24])\n",
        "plt.plot(np.array(df_weather['day cos'])[:24])\n",
        "plt.xlabel('Time [h]')\n",
        "plt.title('Time of day signal')"
      ],
      "metadata": {
        "id": "vEieUA4xW2VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fft = tf.signal.rfft(df_weather['temperature'])\n",
        "f_per_dataset = np.arange(0, len(fft))\n",
        "\n",
        "n_samples_h = len(df_weather['temperature'])\n",
        "hours_per_year = 24*365.2524\n",
        "years_per_dataset = n_samples_h/(hours_per_year)\n",
        "\n",
        "f_per_year = f_per_dataset/years_per_dataset\n",
        "plt.step(f_per_year, np.abs(fft))\n",
        "plt.xscale('log')\n",
        "plt.ylim(0, 200000)\n",
        "plt.xlim([0.01, max(plt.xlim())])\n",
        "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
        "_ = plt.xlabel('Frequency (log scale)')"
      ],
      "metadata": {
        "id": "-oSzLgj1Ra0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie wartości po zmianie"
      ],
      "metadata": {
        "id": "YFKZxL0C-K8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.head()"
      ],
      "metadata": {
        "id": "tY4sNtoV3gSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konwersja temperatury na stopnie Celsjusza"
      ],
      "metadata": {
        "id": "8H9iW97hnAOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather['temperature'] = df_weather['temperature'].apply(lambda x: (x - 273.15))"
      ],
      "metadata": {
        "id": "PtrbQO8ItOfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_timestamp = pd.DataFrame()\n",
        "df_timestamp['datetime'] = pd.to_datetime(df_weather['datetime'])\n",
        "df_weather.drop(columns=['datetime'], inplace=True)"
      ],
      "metadata": {
        "id": "H_HDrwXrkYoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie wartości po zmianie"
      ],
      "metadata": {
        "id": "pvC5qSBm-Nnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.head()"
      ],
      "metadata": {
        "id": "WdfTwwxAkrrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_timestamp.head()"
      ],
      "metadata": {
        "id": "3F8hVjSVkuv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podział na zestawy danych"
      ],
      "metadata": {
        "id": "AuF6TZ--33sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_indices = {name: i for i, name in enumerate(df_weather.columns)}\n",
        "\n",
        "n = len(df_weather)\n",
        "df_train = df_weather[0:int(n*0.7)]\n",
        "df_val = df_weather[int(n*0.7):int(n*0.9)]\n",
        "df_test = df_weather[int(n*0.9):]\n",
        "\n",
        "num_features = df_weather.shape[1]"
      ],
      "metadata": {
        "id": "P7BdCmjt6Ug5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(8)"
      ],
      "metadata": {
        "id": "kqwjCl7_Q2kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalziacja"
      ],
      "metadata": {
        "id": "JpPHDN4EuY1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_mean = df_train.mean()\n",
        "train_std = df_train.std()\n",
        "\n",
        "#tu trzeba pamiętać że wartości z df_train zzapisywane są do train_df\n",
        "\n",
        "# Inicjalziacja ramek danych\n",
        "\n",
        "train_df = pd.DataFrame()\n",
        "val_df = pd.DataFrame()\n",
        "test_df = pd.DataFrame()\n",
        "\n",
        "columns_to_normalize = ['temperature', 'humidity', 'pressure', 'Wx', 'Wy']\n",
        "\n",
        "for col in columns_to_normalize:\n",
        "    train_df[col] = (df_train[col] - train_mean[col]) / train_std[col]\n",
        "    val_df[col] = (df_val[col] - train_mean[col]) / train_std[col]\n",
        "    test_df[col] = (df_test[col] - train_mean[col]) / train_std[col]\n",
        "\n",
        "columns_to_leave_unchanged = ['rain_exists', 'cloud_exists', 'day sin', 'day cos', 'year sin', 'year cos']\n",
        "\n",
        "for col in columns_to_leave_unchanged:\n",
        "    train_df[col] = df_train[col]\n",
        "    val_df[col] = df_val[col]\n",
        "    test_df[col] = df_test[col]"
      ],
      "metadata": {
        "id": "1qDem-quuabz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "vD_BGqs4Qy5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info(verbose=True)"
      ],
      "metadata": {
        "id": "Kx0yLqENO9tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
        "\n",
        "df_std = (df - train_mean) / train_std\n",
        "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
        "#_ = ax.set_xticklabels(df.keys(), rotation=90)\n",
        "tick_positions = range(len(df.keys()))\n",
        "ax.set_xticks(tick_positions)\n",
        "ax.xaxis.set_major_locator(FixedLocator(tick_positions))\n",
        "ax.xaxis.set_major_formatter(FixedFormatter(df.keys()))\n",
        "ax.tick_params(axis='x', rotation=90)"
      ],
      "metadata": {
        "id": "QaPed52quiUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tworzenie okien czasowych"
      ],
      "metadata": {
        "id": "5DlmVFvnYw-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ],
      "metadata": {
        "id": "dq6ftHrxuh5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = WindowGenerator(input_width=24, label_width=1, shift=24,\n",
        "                     label_columns=['temperature'])\n",
        "w1"
      ],
      "metadata": {
        "id": "UTC03IYkY-lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
        "                     label_columns=['temperature'])\n",
        "w2"
      ],
      "metadata": {
        "id": "gAOSkYA2dr8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funkcja dzieląca okna"
      ],
      "metadata": {
        "id": "bgb8kbpT4QJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "    # Operacje wycinania nie zachowują informacji o wymiarach, dlatego ustawiamy wymiary ręcznie. W ten sposób `tf.data.Datasets` są łatwiejsze do inspekcji.\n",
        "\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window"
      ],
      "metadata": {
        "id": "GVd3hLP0dfnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack three slices, the length of the total window.\n",
        "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
        "                           np.array(train_df[100:100+w2.total_window_size]),\n",
        "                           np.array(train_df[200:200+w2.total_window_size])])\n",
        "\n",
        "example_inputs, example_labels = w2.split_window(example_window)\n",
        "\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print(f'Window shape: {example_window.shape}')\n",
        "print(f'Inputs shape: {example_inputs.shape}')\n",
        "print(f'Labels shape: {example_labels.shape}')"
      ],
      "metadata": {
        "id": "WJqinww-dj6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot"
      ],
      "metadata": {
        "id": "qKYT7QCFedbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2.example = example_inputs, example_labels"
      ],
      "metadata": {
        "id": "MG8P5siYefVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(self, model=None, plot_col='temperature', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(max_n, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ],
      "metadata": {
        "id": "eav48nIGegp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2.plot()"
      ],
      "metadata": {
        "id": "rE19WzUaen8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2.plot(plot_col='pressure')"
      ],
      "metadata": {
        "id": "UpCk7qlyfCQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funkcja tworząca datasety"
      ],
      "metadata": {
        "id": "l92qNWKcrzGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=32,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ],
      "metadata": {
        "id": "A-Ra-hnCrxoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ],
      "metadata": {
        "id": "2O4IsaOur7U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2.train.element_spec"
      ],
      "metadata": {
        "id": "2rmVnAsysD-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example_inputs, example_labels in w2.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ],
      "metadata": {
        "id": "qYPcT4p9sIVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recurrent neural network"
      ],
      "metadata": {
        "id": "dQLJuC5qsjDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-output model"
      ],
      "metadata": {
        "id": "r--k0-hvbsil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear - regresja liniowa"
      ],
      "metadata": {
        "id": "Yz0ZN73sdaOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ],
      "metadata": {
        "id": "GBMBywMidZie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_EPOCHS = 20\n",
        "\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ],
      "metadata": {
        "id": "ick_YrRLsYfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    # `WindowGenerator` returns all features as labels if you\n",
        "    # don't set the `label_columns` argument.\n",
        "    input_width=1, label_width=1, shift=1)\n",
        "\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "for example_inputs, example_labels in wide_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ],
      "metadata": {
        "id": "xOTDNX_ar8qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = compile_and_fit(linear, single_step_window)\n",
        "\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
        "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)"
      ],
      "metadata": {
        "id": "mLgh8_u8yaUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wide_window.plot(linear)"
      ],
      "metadata": {
        "id": "jovzK0WDzJp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x = range(len(train_df.columns)),\n",
        "        height=linear.layers[0].kernel[:,0].numpy())\n",
        "axis = plt.gca()\n",
        "axis.set_xticks(range(len(train_df.columns)))\n",
        "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
      ],
      "metadata": {
        "id": "njVsjSsdyVNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:12s}: {value[1]:0.4f}')"
      ],
      "metadata": {
        "id": "tZ9sWOjXzuut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RSS"
      ],
      "metadata": {
        "id": "53223b-4ya12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n"
      ],
      "metadata": {
        "id": "VGNHqpIZbwSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)"
      ],
      "metadata": {
        "id": "mTLWHW6J2uW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wide_window.plot(lstm_model)"
      ],
      "metadata": {
        "id": "T9LXEvF2wnYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wykres porównania średniego błędu bezwzględnego dla modelu regresji liniowej z modelem sieci rekurencyjnej"
      ],
      "metadata": {
        "id": "eJEqEpXY6MrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.ylabel('mean_absolute_error [temperature, normalized]')\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "_ = plt.legend()"
      ],
      "metadata": {
        "id": "ajZc4T6N4HZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wywołanie funkcji forecast_weather z wyuczonym modelem LSTM i oknem"
      ],
      "metadata": {
        "id": "F5PqNOtP6ZRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forecast_weather(model, window, day, hour):\n",
        "    # Utwórz zbiór danych dla określonego dnia\n",
        "    input_data = window.test.take(1)\n",
        "    for inputs, labels in input_data:\n",
        "        # Pobierz dane wejściowe dla określonego dnia i godziny\n",
        "        inputs_for_day_hour = inputs[:, (day - 1) * 24 + hour - window.input_width:(day - 1) * 24 + hour, :]\n",
        "        print(\"inputs_for_day_hour:\", inputs_for_day_hour.shape)\n",
        "        # Przewiduj pogodę dla wybranego dnia i godziny\n",
        "        predictions = model.predict(inputs_for_day_hour)\n",
        "        print(\"Predictions Dimensions:\", predictions.shape)\n",
        "        # Sprawdź, czy tablica predykcji nie jest pusta\n",
        "        if predictions.size == 0:\n",
        "            print(\"Brak dostępnych prognoz dla określonego dnia i godziny.\")\n",
        "            return\n",
        "        # Denormalizuj prognozy, używając średniej i odchylenia standardowego z train_df\n",
        "        units = ['°C', '%', 'MPa', '%', '%', 'm/s', 'm/s']\n",
        "        for i in range(7):\n",
        "            predicted_temperature = predictions[0, 0, i] * train_std[i] + train_mean[i]\n",
        "            print(f\"Predicted {train_std.index[i]}: {predicted_temperature:.2f} {units[i]}\")\n",
        "# Wywołaj funkcję forecast_weather z wyuczonym modelem LSTM i oknem\n",
        "forecast_weather(lstm_model, wide_window, day=2, hour=8)"
      ],
      "metadata": {
        "id": "-v913M99ZuBM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}